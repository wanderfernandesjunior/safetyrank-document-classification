{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yzg7lrQ_v2bP"
   },
   "source": [
    "# EnCompIF 2020\n",
    "\n",
    "## __SafetyRank__: comparação de técnicas de aprendizado de máquina para classificação de alertas de segurança industriais\n",
    "\n",
    "__Bases de dados utilizada:__  \n",
    "- Safety Alerts: elaborada pelo autor composta por 80 documentos em 8 classes (pasta anexa).\n",
    "\n",
    "__Classificadores experimentados:__  \n",
    "- Regressão Logística  \n",
    "- Naive Bayes  \n",
    "- SVM  \n",
    "- KNN  \n",
    "- Árvore de Decisão  \n",
    "- Random Forest   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 1, 1, 0, 3, 6, 6, 5, 1, 2, 1, 3, 4, 4, 0, 5, 2, 5, 1, 6,\n",
       "       1, 3, 2, 2, 5, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregamento do dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Diretorio da base\n",
    "safety_alerts_dir = './safety-alerts-database/'\n",
    "\n",
    "safety_alerts_data = load_files(safety_alerts_dir)\n",
    "\n",
    "safety_alerts_X, safety_alerts_y = safety_alerts_data.data, safety_alerts_data.target\n",
    "\n",
    "safety_alerts_X_train, safety_alerts_X_test, safety_alerts_y_train, safety_alerts_y_test = train_test_split(safety_alerts_X, safety_alerts_y, test_size=0.4)\n",
    "\n",
    "safety_alerts_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQMT54Kcv2bl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Carregamento das bibliotecas comuns do sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezuoem1bv2bu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regressão Logística\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf_logistic_regression = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(penalty='l2', \n",
    "                                                dual=False, \n",
    "                                                tol=0.0001, \n",
    "                                                C=1.0, \n",
    "                                                fit_intercept=True, \n",
    "                                                intercept_scaling=1, \n",
    "                                                class_weight=None, \n",
    "                                                random_state=None, \n",
    "                                                solver='lbfgs', \n",
    "                                                max_iter=1000, \n",
    "                                                multi_class='multinomial', \n",
    "                                                verbose=0, \n",
    "                                                warm_start=False, \n",
    "                                                n_jobs=None, \n",
    "                                                l1_ratio=None)),\n",
    "                     ])\n",
    "\n",
    "#text_clf_logistic_regression.fit(X_train, y_train)\n",
    "#predicted = text_clf_logistic_regression.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPssUdcgv2b2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf_naive_bayes = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=1.0, \n",
    "                                           fit_prior=True, \n",
    "                                           class_prior=None)),\n",
    "                     ])\n",
    "\n",
    "#text_clf_naive_bayes.fit(X_train, y_train)\n",
    "#predicted = text_clf_naive_bayes.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGNTn87Sv2b9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC(penalty='l2', \n",
    "                                       loss='squared_hinge', \n",
    "                                       dual=True, \n",
    "                                       tol=0.0001, \n",
    "                                       C=1.0, \n",
    "                                       multi_class='ovr', # treina n_classes classificadores tipo one-vs-rest\n",
    "                                       fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight=None, \n",
    "                                       verbose=0, \n",
    "                                       random_state=None, \n",
    "                                       max_iter=1000)),\n",
    "                     ])\n",
    "\n",
    "#text_clf_svm.fit(X_train, y_train)\n",
    "#predicted = text_clf_svm.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5InP74wsv2cD",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "text_clf_knn = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=5, \n",
    "                                                  weights='uniform', \n",
    "                                                  algorithm='auto', \n",
    "                                                  leaf_size=30, \n",
    "                                                  p=2, \n",
    "                                                  metric='minkowski', \n",
    "                                                  metric_params=None, \n",
    "                                                  n_jobs=None)),\n",
    "                     ])\n",
    "\n",
    "#text_clf_knn.fit(X_train, y_train)\n",
    "#predicted = text_clf_knn.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txDVjVvlv2cH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Árvore de Decisão\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "text_clf_decision_tree = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', DecisionTreeClassifier(criterion='gini', \n",
    "                                                        splitter='best', \n",
    "                                                        max_depth=None, \n",
    "                                                        min_samples_split=2, \n",
    "                                                        min_samples_leaf=1, \n",
    "                                                        min_weight_fraction_leaf=0.0, \n",
    "                                                        max_features=None, \n",
    "                                                        random_state=None, \n",
    "                                                        max_leaf_nodes=None, \n",
    "                                                        min_impurity_decrease=0.0, \n",
    "                                                        min_impurity_split=None, \n",
    "                                                        class_weight=None, \n",
    "                                                        presort=False)),\n",
    "                         ])\n",
    "\n",
    "#text_clf_decision_tree.fit(X_train, y_train)\n",
    "#predicted = text_clf_decision_tree.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sCZFM6Dv2cL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer(analyzer='word', max_df=0.95, min_df=2,stop_words= 'english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100, \n",
    "                                                    criterion='gini', \n",
    "                                                    max_depth=None, \n",
    "                                                    min_samples_split=2, \n",
    "                                                    min_samples_leaf=1, \n",
    "                                                    min_weight_fraction_leaf=0.0, \n",
    "                                                    max_features='auto', \n",
    "                                                    max_leaf_nodes=None, \n",
    "                                                    min_impurity_decrease=0.0, \n",
    "                                                    min_impurity_split=None, \n",
    "                                                    bootstrap=True, \n",
    "                                                    oob_score=False, \n",
    "                                                    n_jobs=None, \n",
    "                                                    random_state=None, \n",
    "                                                    verbose=0, \n",
    "                                                    warm_start=False, \n",
    "                                                    class_weight=None)),\n",
    "                     ])\n",
    "\n",
    "#text_clf_rf.fit(X_train, y_train)\n",
    "#predicted = text_clf_rf.predict(X_test)\n",
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tpxzFwberoX"
   },
   "outputs": [],
   "source": [
    "# Classe avaliadora de performance dos classificadores (com base no exemplo do Prof. Boldt)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "class PerformanceEvaluator():\n",
    "    \"\"\" Classe avaliadora de performance dos classificadores (com base no exemplo do Prof. Boldt) \n",
    "        Utiliza validação cruzada para o treinamento.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.kf = KFold(n_splits=4)\n",
    "    \n",
    "    def score(self, clf):\n",
    "        scores = []\n",
    "        for train, validate in self.kf.split(self.X_train):\n",
    "            clf.fit(self.X_train[train],self.y_train[train])\n",
    "            scores.append(clf.score(self.X_train[validate],self.y_train[validate]))\n",
    "        return np.mean(scores), np.std(scores)\n",
    "    \n",
    "    def treinar(self, clfs):\n",
    "        print(\"TREINAMENTO (com validação cruzada) - - - - - -\")\n",
    "        print(f'{\"\":>20}  Média \\t Desvio Padrão')\n",
    "        for name,clf in clfs:\n",
    "            score_mean, score_std = self.score(clf)\n",
    "            print(f'{name:>20}: {score_mean:.4f} \\t {score_std:.4f}')\n",
    "\n",
    "    def testar(self, clfs, X_test, y_test):\n",
    "        # Testa os classificadores em dados de teste (não vistos no treinamento)\n",
    "        print(\"TESTE- - - - - - - - - - - - - -- - - - - - - -\")\n",
    "        for name,clf in clfs:\n",
    "            y_pred = clf.predict(X_test)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            print(f'{name:>20}: {score:.4f}')\n",
    "            c = confusion_matrix(y_test, y_pred)\n",
    "            print(c)\n",
    "            print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "DLuIWQkIerod",
    "outputId": "d477d3fa-6464-43bc-f870-270768c1855c"
   },
   "outputs": [],
   "source": [
    "# Avaliação de todos os classificadores\n",
    "\n",
    "clfs = [\n",
    "    ('Logistic Regression', text_clf_logistic_regression),\n",
    "    ('Naive Bayes', text_clf_naive_bayes),\n",
    "    ('SVM', text_clf_svm),\n",
    "    ('KNN', text_clf_knn),\n",
    "    ('Decision Tree', text_clf_decision_tree),\n",
    "    ('Random Forest', text_clf_rf)\n",
    "]\n",
    "\n",
    "#newsgroups_pe = PerformanceEvaluator(np.array(newsgroups_X_train), np.array(newsgroups_y_train))\n",
    "safety_alerts_pe = PerformanceEvaluator(np.array(safety_alerts_X_train), np.array(safety_alerts_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "ur0Mo2pUjOyU",
    "outputId": "4a6996b4-2264-4855-8c2e-951d8a2f0b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREINAMENTO (com validação cruzada) - - - - - -\n",
      "                      Média \t Desvio Padrão\n",
      " Logistic Regression: 0.4773 \t 0.0982\n",
      "         Naive Bayes: 0.3318 \t 0.0775\n",
      "                 SVM: 0.6682 \t 0.1450\n",
      "                 KNN: 0.6432 \t 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n",
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n",
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n",
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Decision Tree: 0.5227 \t 0.1570\n",
      "       Random Forest: 0.4295 \t 0.1448\n",
      "TESTE- - - - - - - - - - - - - -- - - - - - - -\n",
      " Logistic Regression: 0.4286\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 6]\n",
      " [1 0 3 0 0 0 0]\n",
      " [4 0 0 0 1 0 0]\n",
      " [1 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 3 1]\n",
      " [0 0 1 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         3\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.50      0.33      0.40         3\n",
      "           5       1.00      0.75      0.86         4\n",
      "           6       0.20      0.67      0.31         3\n",
      "\n",
      "    accuracy                           0.43        28\n",
      "   macro avg       0.40      0.50      0.40        28\n",
      "weighted avg       0.36      0.43      0.36        28\n",
      "\n",
      "         Naive Bayes: 0.3214\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 6]\n",
      " [1 0 2 0 0 0 1]\n",
      " [5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 2 2]\n",
      " [0 0 1 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      1.00      0.43         3\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.17      0.67      0.27         3\n",
      "\n",
      "    accuracy                           0.32        28\n",
      "   macro avg       0.30      0.38      0.28        28\n",
      "weighted avg       0.29      0.32      0.25        28\n",
      "\n",
      "                 SVM: 0.7500\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 1 2]\n",
      " [0 0 4 0 0 0 0]\n",
      " [0 0 0 5 0 0 0]\n",
      " [0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 4 0]\n",
      " [0 0 1 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      0.17      0.29         6\n",
      "           2       0.67      1.00      0.80         4\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       0.67      0.67      0.67         3\n",
      "           5       0.67      1.00      0.80         4\n",
      "           6       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.79      0.79      0.73        28\n",
      "weighted avg       0.82      0.75      0.71        28\n",
      "\n",
      "                 KNN: 0.6071\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 3]\n",
      " [1 0 2 0 1 0 0]\n",
      " [1 0 0 4 0 0 0]\n",
      " [0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 4 0]\n",
      " [0 0 1 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      0.17      0.29         6\n",
      "           2       0.50      0.50      0.50         4\n",
      "           3       0.80      0.80      0.80         5\n",
      "           4       0.33      0.33      0.33         3\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.65      0.64      0.59        28\n",
      "weighted avg       0.71      0.61      0.58        28\n",
      "\n",
      "       Decision Tree: 0.7500\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 2 1 2 0 1 0]\n",
      " [0 0 4 0 0 0 0]\n",
      " [0 0 0 4 1 0 0]\n",
      " [0 0 0 0 3 0 0]\n",
      " [0 0 0 0 1 3 0]\n",
      " [0 1 0 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.67      0.33      0.44         6\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       0.67      0.80      0.73         5\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       0.75      0.75      0.75         4\n",
      "           6       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.78      0.79      0.77        28\n",
      "weighted avg       0.76      0.75      0.73        28\n",
      "\n",
      "       Random Forest: 0.4643\n",
      "[[3 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 3 1]\n",
      " [0 0 2 0 2 0 0]\n",
      " [0 0 0 0 5 0 0]\n",
      " [0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 4 0]\n",
      " [0 0 1 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.18      0.67      0.29         3\n",
      "           5       0.50      1.00      0.67         4\n",
      "           6       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.46        28\n",
      "   macro avg       0.43      0.55      0.46        28\n",
      "weighted avg       0.36      0.46      0.39        28\n",
      "\n",
      "CPU times: user 1.98 s, sys: 40.2 ms, total: 2.02 s\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/karin/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Treina os classificadores usando validação cruzada na base de Alertas de Seguranca\n",
    "safety_alerts_pe.treinar(clfs)\n",
    "\n",
    "# Testa os classificadores em dados de teste (não vistos no treinamento)\n",
    "safety_alerts_pe.testar(clfs, np.array(safety_alerts_X_test), np.array(safety_alerts_y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[Qualificação] Classificação 20newsgroups.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
